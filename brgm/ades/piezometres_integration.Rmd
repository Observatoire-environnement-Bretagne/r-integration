---
title: "Integration des données piezometriques"
output: html_notebook
params:
  reseau_piezo: '0400000020'
  date_debut: 2021-12-01
  date_fin: 2022-02-28
  pagination: 5000
  path_dataviz: 'O:/04.DATAVISUALISATION/PIEZO_NIVEAU_NAPPES/BULLETIN PIEZO_SOURCE'
  path_source: 'O:\01.BD_EAU\BRGM\BULLETIN PIEZO'
  fichier_mensuel: 'Points_reseauPz_fev22.xlsx'
  
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library(config) # Utilisation d'un fichier de configuration, cf  https://db.rstudio.com/best-practices/managing-credentials/#stored-in-a-file-with-config
library(tidyverse)
library(DBI) # pour les connexions aux BDD
library(RPostgreSQL) # driver postgres
library(RMariaDB) # driver MariaDB
library(RMySQL) # driver MySQL
library(lubridate) # calcul sur les dates

library(httr) #
library(jsonlite) # Gestion format json

library("readxl") # Lecture de fichiers xlsx

# Fonction pour traduire la réponse de l'API
api_reponse <- function(request) {
  
case_when(request$status_code==200 ~ "OK, tous les résultats sont présents dans la réponse",
          request$status_code==206 ~ "OK, il reste des résultats",
          request$status_code==400 ~ "Requête incorrecte",
            TRUE ~ "Autre réponse")
}

# Fonction pour requêter l'API Hub'Eau

get_hubeau <- function(path, query) {
  
  response <- GET(url = path, query = query) %>% 
  content(as = "text", encoding = "UTF-8") %>%
  fromJSON(flatten = TRUE)
  
data = response$data # Le jeu de données est dans l'objet "data"

if(response$count > query$size) { # Si la taille de page est plus petite que le nb de résultats, faire une boucle pour les pages suivantes
  
pages <- ceiling(response$count/query$size)

# Affichage d'une barre de progression
pb <- winProgressBar(title = "Récupération des chroniques", min = 0,
                     max = pages, width = 300)

for(i in 2:pages){
  
  query$page <- i
  
  response_i <- GET(url = path, query = query) %>% 
  content(as = "text", encoding = "UTF-8") %>%
  fromJSON(flatten = TRUE)

data <- rbind(data, response_i$data) # Concaténation des lignes récupérées

setWinProgressBar(pb, i, title=paste( round(i/pages*100, 0), "% chargé")) # Avancement de la barre de progression

} # Fin boucle for

close(pb)

} # Fin if

return(data)
  } # Fin get_hubeau

# Insertion de données

db.insertion <- function(con,table,data) {
  
  # Date de la dernière donnée en base
  Date_max <- tbl(con, table) %>% summarise(Date_max = max(Date_de_la_mesure, na.rm = TRUE)) %>% pull(Date_max)
  if(is.na(Date_max)) Date_max <- as.Date(params$date_debut)-1
  
  # Données plus récentes à insérer
  data <- data %>% filter(Date_de_la_mesure > Date_max)
  
  # Existe-t-il des données à insérer ?
if (isTRUE(data %>% tally() > 0)) {
  
  # Insertion des nouvelles lignes
  dbWriteTable(con, table, data, overwrite=FALSE, append=TRUE,
             fileEncoding="latin1")
  
  # Horodate en commentaire
mise_a_jour <- paste0(format.Date(Sys.Date(),"%d/%m/%Y"), " : Actualisation ",params$actualisation)

dbExecute(con, paste0("ALTER TABLE ",table," COMMENT = '",mise_a_jour,"';"))

paste0("Données insérées : ",data%>%tally)

}
  else {
    
    paste0("Aucune donnée à insérer depuis le ", format.Date(Date_max,"%d/%m/%Y"))
  
    }
  
} # fin db.insertion
```


```{r connexion_bd}

conf <- config::get("mysql_local")

# con_mysql_local <- dbConnect(odbc::odbc(),
#                              Driver=conf$driver,
#                              host = conf$host,
#                              UID = conf$uid,
#                              PWD = conf$pwd,
#                              port = conf$port,
#                              timeout = 10,
#                              database = "oeb_piezo_variation_nappes",
#                              encoding = "latin1")

con_mysql_oeb <- dbConnect(RMariaDB::MariaDB(), default.file = '../../.my.cnf', groups="mysql_oeb",
dbname = "eau_piezo_variation_nappes")


dbListTables(con_mysql_oeb) # Lister les tables de la base

conf <- config::get("postgres_dev")

con_postgresql_dev <- DBI::dbConnect(odbc::odbc(),
                          Driver       = conf$driver,
                          servername   = conf$server,
                          UID = conf$uid,
                          PWD = conf$pwd,
                          Port = conf$port,
                          database = 'eau',
                             encoding = "latin1")
```

```{r piezometres}
# Recupération de la liste des piézomètres du réseau breton dans la base de données

db_piezometres <- tbl(con_mysql_oeb, "oeb_tbi_variationnappe_pz") # Lecture de la table des piezometres

db_piezometres %>% tally() #56 piezometres

liste_codes_bss <- db_piezometres %>% collect() %>%
  summarise(Code_national_BSS = str_flatten(Code_national_BSS, collapse = ",")) # Liste des piezometres pour la requete

```

```{r hubeau}

# Récupération des infos sur les stations de mesure

# Liste des paramètres de la requête
query_stations = list(
  code_bss=liste_codes_bss,
  format='json',
  size=params$pagination
  )

# Requête des stations
hubeau_stations <- get_hubeau(path = "https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/stations?", query = query_stations)

# Récupération des chroniques

# Liste des paramètres de la requête
query_chroniques = list(
                 code_bss = liste_codes_bss,
                 format = 'json',
                 size = params$pagination,
                 date_debut_mesure = params$date_debut,
                 date_fin_mesure = as.Date(params$date_fin))

# Requête des chroniques
hubeau_chroniques <- get_hubeau(path = "https://hubeau.eaufrance.fr/api/v1/niveaux_nappes/chroniques?", query=query_chroniques)
```

```{r}
all_equal(db_piezometres, hubeau_stations)

# Piezometres sans ID ?
db_piezometres %>% collect() %>%
  left_join(hubeau_stations, by=c("Code_national_BSS" = "code_bss"))%>%
  filter(is.na(bss_id))%>%
  select(Code_national_BSS)
  
```


```{r}
hubeau_chroniques %>%
  ggplot(aes(date_mesure, profondeur_nappe, color=code_bss, group_by(code_bss)))+
  geom_point()
```

```{r table oeb_tbi_variationnappe_tmp}

# Reconstitution de la table d'integration
oeb_tbi_variationnappe_tmp <- hubeau_chroniques %>%
  left_join(hubeau_stations, by="code_bss")%>% 
  mutate(
Date_de_la_mesure = as.POSIXct(timestamp_mesure/1000, origin="1970-01-01", tz = "UTC"),
Code_qualification = 1,
Profondeur_d_but_site_de_mesure = NA,
Profondeur_fin_site_de_mesure = NA,
Mois = format.Date(date_mesure,"%m"),
Annee = format.Date(date_mesure,"%Y"),
Dateintegration = format.Date(Sys.Date(),"%Y-%m-%d")) %>%
    select(
Code_national_BSS = code_bss,
Date_de_la_mesure,
Profondeur_relative_rep_re_de_mesure = profondeur_nappe,
C_te_NGF = niveau_nappe_eau,
Code_qualification,
Qualification_de_la_mesure = qualification,
Continuit_ = nom_continuite,
Mode_obtention = mode_obtention,
Statut_de_la_mesure = statut,
Profondeur_d_but_site_de_mesure,
Profondeur_fin_site_de_mesure,
X_WGS84 = x,
Y_WGS84 = y,
Producteur_de_donn_es = nom_producteur,
Mois,
Annee,
Dateintegration)

oeb_tbi_variationnappe_tmp
```

# Insertion des données (le code n'est pas exécuté automatiquement)

```{r eval=FALSE, include=FALSE}
db.insertion(con = con_mysql_oeb, table = "oeb_tbi_variationnappe_tmp", data = oeb_tbi_variationnappe_tmp)

# 2021-07-08 : 1453 lignes insérées pour juin 2021
# 2021-08-16 : 1559 lignes insérées pour juillet 2021
# 2021-09-07 : 1521 lignes insérées pour août 2021
# 2021-10-04 : 1487 lignes insérées pour septembre 2021
# 2021-12-10 : 1532 lignes insérées pour octobre 2021
# 2021-12-10 : 1493 lignes insérées pour novembre 2021
# 2022-03-07 : 4521 lignes insérées pour février 2022
```
# Import des fichiers d'expertise du BRGM

## Création de la base de données à partir du Fichier cumulé



```{r import_Point_Reseau_Evolution}

fichier <- "OEB_Point_Reseau_Evolution.xlsx"
sheets <- excel_sheets(path=paste0(params$path_source,'/',fichier[1]))

import_reseau_evolution <- read_xlsx(paste0(params$path_source,'/',fichier), 
          sheet=sheets[1])

import_reseau_evolution
```

```{r write_table_nappe_etat_mensuel, eval=FALSE, include=FALSE}

# Migration de la table d'expertise du BRGM à partir du fichier excel

# Lecture des tables de dimensions

calendrier <- tbl(con_postgresql_dev, dbplyr::in_schema("eau_structure","date")) # Lecture du calendrier dans le référentiel

series <- tbl(con_postgresql_dev, dbplyr::in_schema("eau_structure","serie")) # Lecture des noms de séries de données

sites <- tbl(con_postgresql_dev, dbplyr::in_schema("eau_structure","site"))%>% filter(typesite_id == 4) %>% mutate(code = substr(code, 1,10))

# Formatage des données pour la table des résultats par site
import_nappe_etat_mensuel <- import_reseau_evolution %>%
  left_join(select(calendrier,date_du_jour,mm_yyyy,dernier_jour_du_mois), by=c('periode'='date_du_jour'), copy = TRUE) %>%
  select(site_code = Num_BSS, 
         periode = mm_yyyy,
         dernier_jour_du_mois,
         Niveau,
         Evolution)%>%
  pivot_longer(cols=c("Niveau","Evolution"), names_to = 'Serie', values_to='Resultat') %>%
  mutate(Serie_code=case_when(Serie == "Niveau" ~ "nappe_niveau_mensuel_expertise",
                         Serie == "Evolution" ~ "nappe_variation_mensuelle_expertise"),
         date_id=format.Date(as.Date(dernier_jour_du_mois),"%Y%m%d"),
         source = 'BRGM',
         maj = Sys.Date())%>%
  left_join(select(series,serie_id,code), by=c("Serie_code" = "code"), copy = TRUE)%>%
  left_join(select(sites,site_id,code), by=c("site_code" = "code"), copy = TRUE)%>%
  select(site_id,periode,date_id,serie_id,resultat = Resultat,source,maj)

# Ecriture en base
  #dbWriteTable(con_postgresql_dev, SQL("eau_structure.nappe_etat_mensuel"), import_nappe_etat_mensuel, overwrite=FALSE, append=TRUE, fileEncoding="latin1")


import_nappe_etat_mensuel
```

# Import du fichier d'expertise mensuelle sur le niveau des nappes

```{r import_bulletin_piezo}


# Lecture des tables de dimensions dans le schema referentiel

calendrier <- tbl(con_postgresql_dev, dbplyr::in_schema("eau_structure","date")) # Lecture du calendrier dans le référentiel

series <- tbl(con_postgresql_dev, dbplyr::in_schema("eau_structure","serie")) # Lecture des noms de séries de données

sites <- tbl(con_postgresql_dev, dbplyr::in_schema("eau_structure","site"))%>% filter(typesite_id == 4) %>% mutate(code = substr(code, 1,10))

# Import du fichier excel

# abbreviation du mois utilisée pour le nom de fichier
mois_ab <- c("janv", "fev", "mars", "avril", "mai", "juin", "juill", "aout", "sep", "oct", "nov", "dec")

fichier <- paste0("Points_reseauPz_",mois_ab[as.integer(format.Date(params$date_fin,"%m"))],format.Date(params$date_fin,"%y"),".xlsx")
sheets <- excel_sheets(path=paste0(params$path_source,'/',fichier[1]))

import_bulletin_piezo <- read_xlsx(paste0(params$path_source,'/',fichier), 
          sheet=sheets[1])%>%
  mutate(site_code = str_remove_all(Num_BSS, "-"),
         date_du_jour = as.Date(params$date_debut)) %>%
  pivot_longer(cols=c("Niveau","Evolution"), names_to = 'Serie', values_to='Resultat') %>%
  mutate(Serie=case_when(Serie == "Niveau" ~ "nappe_niveau_mensuel_expertise",
                         Serie == "Evolution" ~ "nappe_variation_mensuelle_expertise")) %>%
  # Jointure des id de séries
  left_join(select(series,serie_id,code), by=c("Serie" = "code"), copy = TRUE) %>%
  # Jointure des id de sites
  left_join(select(sites,site_id,code), by=c("site_code" = "code"), copy = TRUE)%>%
  # Jointure des id de date
  left_join(select(calendrier,date_du_jour,mm_yyyy,dernier_jour_du_mois), by='date_du_jour', copy = TRUE)%>%
  # id de date à partir du dernier jour du mois
  mutate(date_id=format.Date(as.Date(dernier_jour_du_mois),"%Y%m%d"),
                             source = 'BRGM',
                             maj = Sys.Date())%>%
  # Sélection des champs du schema
  select(site_id,periode=mm_yyyy,date_id,serie_id,resultat = Resultat, source, maj)

import_bulletin_piezo

```

```{r ecriture_bulletin_mensuel, eval=FALSE, include=FALSE}
# Ecriture en base

dbWriteTable(con_postgresql_dev, SQL("eau_structure.nappe_etat_mensuel"), import_bulletin_piezo, overwrite=FALSE, append=TRUE, fileEncoding="latin1")
```



